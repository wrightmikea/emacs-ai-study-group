#+TITLE: Ellama Interactive Demo
#+AUTHOR: Emacs AI Study Group
#+DATE: [2025-01-03]
#+PROPERTY: header-args:emacs-lisp :results output :exports both
#+PROPERTY: header-args:shell :results output :exports both
#+STARTUP: showeverything

* Introduction

This document provides a hands-on, reproducible demonstration of Ellama, an Emacs
tool for interacting with Large Language Models via Ollama.

*Prerequisites:*
- Ollama installed: https://ollama.ai/
- At least one model pulled: =ollama pull llama3.2=
- Ellama package installed in Emacs

*What is Ellama?*
Ellama provides a comprehensive Emacs interface for AI-assisted tasks including:
- Interactive chat sessions
- Code generation and refactoring
- Text translation and summarization
- Context-aware assistance

*How to use this document:*
1. Position cursor in any code block
2. Press =C-c C-c= to execute the code
3. Results will appear below the code block

* Environment Setup

** Bootstrap Package System (Required for emacs -Q)

If you're running this with =emacs -Q=, execute this block first to set up the package system:

#+BEGIN_SRC emacs-lisp
;; Initialize package.el
(require 'package)

;; Add MELPA if not already present
(unless (assoc "melpa" package-archives)
  (add-to-list 'package-archives '("melpa" . "https://melpa.org/packages/") t))

;; Initialize packages
(unless package--initialized
  (package-initialize))

;; Refresh package contents if needed
(unless package-archive-contents
  (message "Refreshing package archive contents...")
  (package-refresh-contents))

(message "‚úì Package system initialized with MELPA")
#+END_SRC

** Install Ellama and Dependencies (If Not Already Installed)

#+BEGIN_SRC emacs-lisp
;; Install llm (dependency)
(unless (package-installed-p 'llm)
  (message "Installing llm package...")
  (condition-case err
      (progn
        (package-install 'llm)
        (message "‚úì llm installed successfully"))
    (error
     (message "‚úó Failed to install llm: %s" err))))

;; Install ellama
(unless (package-installed-p 'ellama)
  (message "Installing ellama from MELPA...")
  (condition-case err
      (progn
        (package-install 'ellama)
        (message "‚úì ellama installed successfully"))
    (error
     (message "‚úó Failed to install ellama: %s" err))))

;; Load packages
(require 'llm nil t)
(require 'ellama nil t)

(if (and (featurep 'llm) (featurep 'ellama))
    (message "‚úì Ellama and dependencies are loaded and ready!")
  (message "‚úó Some packages could not be loaded"))
#+END_SRC

** Check Ollama Installation

#+BEGIN_SRC shell
if command -v ollama &> /dev/null; then
    echo "‚úì Ollama found at: $(which ollama)"
    echo "Version: $(ollama --version)"
else
    echo "‚úó Ollama not found. Install from: https://ollama.ai/"
fi
#+END_SRC

** List Available Models

#+BEGIN_SRC shell
echo "Available Ollama models:"
ollama list 2>/dev/null || echo "No models found. Try: ollama pull llama3.2"
#+END_SRC

** Check Ollama Service

#+BEGIN_SRC shell
curl -s http://localhost:11434/api/tags 2>/dev/null && \
    echo "‚úì Ollama service is running" || \
    echo "‚úó Ollama service not running. Start with: ollama serve"
#+END_SRC

** Verify Ellama Installation

#+BEGIN_SRC emacs-lisp
(if (featurep 'ellama)
    (message "‚úì Ellama is loaded")
  (if (locate-library "ellama")
      (progn
        (require 'ellama)
        (message "‚úì Ellama loaded successfully"))
    (message "‚úó Ellama not found. Install from MELPA.")))
#+END_SRC

** Check LLM Package

Ellama requires the llm package as a dependency:

#+BEGIN_SRC emacs-lisp
(if (featurep 'llm)
    (message "‚úì llm package is loaded")
  (if (locate-library "llm")
      (progn
        (require 'llm)
        (message "‚úì llm package loaded"))
    (message "‚úó llm package not found. It's required for Ellama.")))
#+END_SRC

* Basic Configuration

** View Current Configuration

#+BEGIN_SRC emacs-lisp
(with-eval-after-load 'ellama
  (message "Current Ellama Configuration:

Provider: %s
Model: %s
Sessions Directory: %s
Auto-save: %s
Language: %s
Naming Scheme: %s"
           (if (boundp 'ellama-provider)
               (type-of ellama-provider)
             "Not configured")
           (if (boundp 'ellama-provider)
               (condition-case nil
                   (oref ellama-provider chat-model)
                 (error "N/A"))
             "N/A")
           (if (boundp 'ellama-sessions-directory)
               ellama-sessions-directory
             "Not set")
           (if (boundp 'ellama-auto-save)
               ellama-auto-save
             "Not set")
           (if (boundp 'ellama-language)
               ellama-language
             "Not set")
           (if (boundp 'ellama-naming-scheme)
               ellama-naming-scheme
             "Not set")))
#+END_SRC

** Configure Ollama Provider

#+BEGIN_SRC emacs-lisp
(require 'llm-ollama)
(require 'ellama)

;; Basic configuration
(setopt ellama-provider
        (make-llm-ollama
         :chat-model "llama3.2:latest"
         :embedding-model "nomic-embed-text"))

(setopt ellama-language "English")

(message "‚úì Ellama configured with llama3.2 model")
#+END_SRC

* Available Commands

** List All Ellama Commands

#+BEGIN_SRC emacs-lisp
(let ((commands '()))
  (mapatoms
   (lambda (symbol)
     (when (and (commandp symbol)
                (string-prefix-p "ellama-" (symbol-name symbol)))
       (push (cons symbol (documentation symbol)) commands))))
  (message "Ellama Commands (%d total):\n\n%s"
           (length commands)
           (mapconcat
            (lambda (cmd)
              (format "%-35s\n  %s"
                      (car cmd)
                      (or (car (split-string (or (cdr cmd) "No description") "\n"))
                          "No description")))
            (seq-sort (lambda (a b) (string< (symbol-name (car a))
                                             (symbol-name (car b))))
                      commands)
            "\n\n")))
#+END_SRC

** Command Categories

#+BEGIN_SRC emacs-lisp
(defun demo-command-categories ()
  "Display Ellama commands organized by category."
  (interactive)
  (message "Ellama Command Categories:

üìù CHAT & INTERACTION
  ellama-chat              - Start interactive chat
  ellama-ask-about         - Ask about specific topic
  ellama-ask-line          - Ask about current line
  ellama-ask-selection     - Ask about selected region

üí¨ TEXT OPERATIONS
  ellama-translate         - Translate text
  ellama-define-word       - Define word at point
  ellama-summarize         - Summarize text
  ellama-improve-wording   - Improve text wording
  ellama-improve-grammar   - Fix grammar
  ellama-make-list         - Convert to list format
  ellama-make-format       - Reformat text

üíª CODE OPERATIONS
  ellama-code-edit         - Edit code with AI
  ellama-code-add          - Add code functionality
  ellama-code-improve      - Improve code quality
  ellama-code-complete     - Complete code
  ellama-code-review       - Review code

üé® CONTENT GENERATION
  ellama-render            - Render markdown/org
  ellama-complete          - Complete current text

‚öôÔ∏è  SESSION MANAGEMENT
  ellama-load-session      - Load saved session
  ellama-session-remove    - Remove session
  ellama-chat-done         - Finish current chat"))

(demo-command-categories)
#+END_SRC

* Basic Usage Examples

** Example 1: Simple Chat

#+BEGIN_SRC emacs-lisp
(defun demo-simple-chat ()
  "Demonstrate basic chat usage."
  (interactive)
  (message "Simple Chat Example:

1. Start chat: M-x ellama-chat
2. Type your question
3. Press C-c C-c to send
4. Wait for response
5. Continue conversation

Try it now:
  M-x ellama-chat

Example questions:
  - 'Explain how closures work in Emacs Lisp'
  - 'What's the difference between defun and defmacro?'
  - 'Show me an example of using hooks'

Tips:
  - Use C-c C-c to send message
  - Session is automatically saved
  - Previous chats can be loaded with M-x ellama-load-session"))

(demo-simple-chat)
#+END_SRC

** Example 2: Ask About Selection

Create some example text and ask about it:

#+BEGIN_SRC emacs-lisp
(defun demo-ask-selection ()
  "Demonstrate asking about selected text."
  (interactive)
  (with-temp-buffer
    (insert "(defun factorial (n)
  (if (<= n 1)
      1
    (* n (factorial (- n 1)))))")
    (message "Example: Ask About Selection

Sample code:
%s

Steps:
1. Select/highlight the text (mark region)
2. M-x ellama-ask-selection
3. Enter your question, e.g.:
   - 'Explain this function'
   - 'Is this tail-recursive?'
   - 'How can I optimize this?'
   - 'Add error handling'

Ellama will analyze the selection and respond with context."
             (buffer-string))))

(demo-ask-selection)
#+END_SRC

** Example 3: Code Improvement

#+BEGIN_SRC emacs-lisp
(defun demo-code-improvement ()
  "Demonstrate code improvement features."
  (interactive)
  (let ((sample-code "(defun add-nums (a b)
  (+ a b))"))
    (message "Code Improvement Example:

Original code:
%s

Using ellama-code-improve:
1. Place cursor in function
2. M-x ellama-code-improve
3. Specify improvements:
   'Add docstring, type hints, and error handling'

Expected result:
(defun add-nums (a b)
  \"Add two numbers A and B.
Return their sum as a number.\"
  (unless (and (numberp a) (numberp b))
    (error \"Both arguments must be numbers\"))
  (+ a b))

Try other code commands:
  - ellama-code-review: Get code review
  - ellama-code-edit: Make specific changes
  - ellama-code-add: Add new functionality"
             sample-code)))

(demo-code-improvement)
#+END_SRC

** Example 4: Text Translation

#+BEGIN_SRC emacs-lisp
(defun demo-translation ()
  "Demonstrate translation features."
  (interactive)
  (message "Translation Example:

1. Write or select text in any language
2. M-x ellama-translate
3. Specify target language

Example:
  Text: 'Hello, how are you?'
  Command: M-x ellama-translate
  Prompt: 'Translate to Spanish'
  Result: 'Hola, ¬øc√≥mo est√°s?'

Set default language:
  (setopt ellama-language \"Spanish\")

Then just M-x ellama-translate without specifying language.

Supports any language Ollama model understands:
  - Spanish, French, German, Italian
  - Chinese, Japanese, Korean
  - And many more!"))

(demo-translation)
#+END_SRC

* Advanced Features

** Working with Different Models

#+BEGIN_SRC emacs-lisp
(defun demo-model-switching ()
  "Demonstrate how to work with different models."
  (interactive)
  (message "Working with Different Models:

Available model options:

1. General Purpose:
   llama3.2:latest    - Balanced, good for chat
   llama2:latest      - Stable, well-tested

2. Code-Focused:
   codellama:latest   - Specialized for coding
   deepseek-coder     - Excellent code understanding
   starcoder2         - Code generation

3. Fast Models:
   mistral:latest     - Fast responses
   phi                - Small, efficient

4. Specialized:
   nous-hermes        - Instruction following
   wizardcoder        - Advanced coding

Switch models:

(setopt ellama-provider
        (make-llm-ollama
         :chat-model \"codellama:latest\"
         :embedding-model \"nomic-embed-text\"))

Pull new models:
  shell: ollama pull codellama
  shell: ollama pull deepseek-coder"))

(demo-model-switching)
#+END_SRC

** Session Management

#+BEGIN_SRC emacs-lisp
(defun demo-session-management ()
  "Demonstrate session management features."
  (interactive)
  (message "Session Management:

Automatic Saving:
  (setopt ellama-auto-save t)
  All chats are automatically saved

Session Location:
  Default: %s
  Customize: (setopt ellama-sessions-directory \"~/my-ai-chats\")

Naming Strategies:
  1. Generated by LLM:
     (setopt ellama-naming-scheme 'ellama-generate-name-by-llm)
     ‚Üí AI generates descriptive name

  2. Current timestamp:
     (setopt ellama-naming-scheme 'ellama-generate-name-by-time)
     ‚Üí Uses timestamp: 2025-01-03-14-30-00

  3. Custom function:
     (setopt ellama-naming-scheme
             (lambda () (format \"chat-%%s\" (random 10000))))

Loading Sessions:
  M-x ellama-load-session
  ‚Üí Select from list of previous chats

Removing Sessions:
  M-x ellama-session-remove
  ‚Üí Delete unwanted sessions

List sessions:
  ls %s"
           (if (boundp 'ellama-sessions-directory)
               ellama-sessions-directory
             "~/.emacs.d/ellama-sessions")
           (if (boundp 'ellama-sessions-directory)
               ellama-sessions-directory
             "~/.emacs.d/ellama-sessions")))

(demo-session-management)
#+END_SRC

** Context and Memory

#+BEGIN_SRC emacs-lisp
(defun demo-context-memory ()
  "Explain context and memory features."
  (interactive)
  (message "Context and Memory in Ellama:

How Context Works:
- Ellama maintains conversation history
- Previous messages inform new responses
- Context is preserved in sessions

Using Context Effectively:

1. Build on Previous Responses:
   You: 'Explain closures'
   AI: [explains closures]
   You: 'Show me an example'  ‚Üê Uses previous context
   You: 'Now make it thread-safe' ‚Üê Continues context

2. Reference Earlier Code:
   You: 'Write a function to parse JSON'
   AI: [provides function]
   You: 'Add error handling to that function' ‚Üê Knows which one

3. Iterative Refinement:
   You: 'Write a todo list manager'
   AI: [basic version]
   You: 'Add priority levels'
   You: 'Add due dates'
   You: 'Add persistence'
   Each builds on previous version

Context Limitations:
- Limited by model's context window
- Very long conversations may lose early context
- Start new chat for unrelated topics

Clear Context:
- Start fresh: M-x ellama-chat (new session)
- Or load different session"))

(demo-context-memory)
#+END_SRC

* Practical Workflows

** Workflow 1: Code Refactoring

#+BEGIN_SRC emacs-lisp
(defun demo-refactoring-workflow ()
  "Complete refactoring workflow example."
  (interactive)
  (let ((legacy-code "(defun process-data (data)
  (let ((result '()))
    (dolist (item data)
      (if (not (null item))
          (if (> (length item) 0)
              (push (upcase item) result))))
    (reverse result)))"))
    (message "Refactoring Workflow:

Step 1: Review Original Code
%s

Step 2: Select code and run M-x ellama-code-review
Response will identify issues:
  - Multiple nested ifs (hard to read)
  - Manual list building (not idiomatic)
  - No documentation
  - No error handling

Step 3: Run M-x ellama-code-improve
Request: 'Make this more functional and add documentation'

Result:
(defun process-data (data)
  \"Process DATA by filtering and upcasing non-empty strings.
DATA should be a list of strings or nils.
Returns a new list with uppercased non-empty strings.\"
  (seq-filter #'identity
              (mapcar (lambda (item)
                        (when (and item (not (string-empty-p item)))
                          (upcase item)))
                      data)))

Step 4: Verify with tests
M-x ellama-code-add
Request: 'Add ert unit tests for this function'

Step 5: Document
M-x ellama-ask-selection
Question: 'Explain the improvements made'"
             legacy-code)))

(demo-refactoring-workflow)
#+END_SRC

** Workflow 2: Learning New Concepts

#+BEGIN_SRC emacs-lisp
(defun demo-learning-workflow ()
  "Demonstrate learning workflow with Ellama."
  (interactive)
  (message "Learning Workflow:

Scenario: Learning about Emacs advice system

Step 1: Start Chat
  M-x ellama-chat
  'Explain Emacs advice system'

Step 2: Get Examples
  'Show me a simple example'
  AI provides code example

Step 3: Understand Specifics
  'What's the difference between :before and :after advice?'
  'When should I use :around advice?'

Step 4: Practice
  'Give me an exercise: write advice for message function'
  Try it yourself, then ask for feedback

Step 5: Real-World Application
  'Show me how to use advice to debug a function'
  'How do I remove advice later?'

Step 6: Save Learning
  Session is auto-saved
  Return later: M-x ellama-load-session

Benefits:
‚úì Interactive Q&A
‚úì Immediate examples
‚úì Progressive learning
‚úì Saves conversation for reference"))

(demo-learning-workflow)
#+END_SRC

** Workflow 3: Documentation Generation

#+BEGIN_SRC emacs-lisp
(defun demo-documentation-workflow ()
  "Demonstrate documentation generation workflow."
  (interactive)
  (message "Documentation Workflow:

Scenario: Document an undocumented function

Step 1: Select function
(defun calculate-stats (numbers)
  (list (apply '+ numbers)
        (/ (apply '+ numbers) (length numbers))
        (apply 'max numbers)))

Step 2: Generate docstring
  M-x ellama-code-improve
  'Add comprehensive docstring'

Step 3: Generate usage examples
  M-x ellama-ask-selection
  'Provide usage examples'

Step 4: Generate README section
  M-x ellama-ask-selection
  'Write a README section for this function'

Step 5: Generate tests
  M-x ellama-code-add
  'Add ert tests with edge cases'

Result: Fully documented and tested function!

Batch processing:
  For multiple functions:
  1. Select all functions
  2. M-x ellama-code-improve
  3. 'Add docstrings to all functions'"))

(demo-documentation-workflow)
#+END_SRC

** Workflow 4: Interactive Debugging

#+BEGIN_SRC emacs-lisp
(defun demo-debugging-workflow ()
  "Demonstrate debugging workflow."
  (interactive)
  (let ((buggy-code "(defun parse-config (file)
  (with-temp-buffer
    (insert-file-contents file)
    (json-read)))"))
    (message "Debugging Workflow:

Buggy Code:
%s

Problem: Crashes on missing file

Step 1: Analyze
  M-x ellama-ask-selection
  'What are potential bugs in this code?'

AI Response:
  - No error handling for missing files
  - No validation of JSON format
  - Doesn't require json library

Step 2: Fix
  M-x ellama-code-edit
  'Add proper error handling and validation'

Step 3: Test edge cases
  M-x ellama-code-add
  'Add tests for: missing file, invalid JSON, empty file'

Step 4: Verify
  Run tests, iterate if needed

Step 5: Document
  M-x ellama-code-improve
  'Add docstring explaining error behavior'

Interactive debugging:
  - Ask 'why' questions
  - Request explanations
  - Get alternative approaches
  - Learn as you debug"
             buggy-code)))

(demo-debugging-workflow)
#+END_SRC

* Tips and Best Practices

** Effective Prompting

#+BEGIN_SRC emacs-lisp
(defun demo-prompting-tips ()
  "Tips for effective prompting with Ellama."
  (interactive)
  (message "Effective Prompting Tips:

‚úì BE SPECIFIC
  Bad:  'Fix this code'
  Good: 'Add error handling for nil inputs'

‚úì PROVIDE CONTEXT
  Bad:  'Optimize this'
  Good: 'Optimize this for large lists (>10000 items)'

‚úì ASK FOR EXAMPLES
  'Show me an example of...'
  'Demonstrate how to...'

‚úì ITERATE
  Start simple, refine progressively:
  1. 'Write a cache function'
  2. 'Add TTL support'
  3. 'Add size limits'
  4. 'Add LRU eviction'

‚úì REQUEST EXPLANATIONS
  'Explain why you chose this approach'
  'What are the trade-offs?'

‚úì USE FOLLOW-UP QUESTIONS
  'Can you simplify that?'
  'What if the input is invalid?'

‚úì SPECIFY STYLE
  'Use functional programming style'
  'Follow elisp conventions'
  'Add comprehensive comments'

‚úó AVOID VAGUE REQUESTS
  'Make it better' - Better how?
  'Fix bugs' - Which bugs?"))

(demo-prompting-tips)
#+END_SRC

** Common AI Mistakes with Emacs Lisp

Local models (like those used by Ellama) often confuse Lisp dialects. Here's how to spot and fix these issues:

#+BEGIN_SRC emacs-lisp
(defun demo-common-ai-mistakes ()
  "Common mistakes AI makes with Emacs Lisp."
  (interactive)
  (message "Common AI Mistakes to Watch For:

üö® CRITICAL: Common Lisp vs Emacs Lisp Confusion

Local models are especially prone to this confusion!

‚ùå WRONG (Common Lisp):
(defun print-items (items)
  (loop for item in items
    do (format t \"%%s\\n\" item)))  ; Common Lisp syntax!

‚úì CORRECT (Emacs Lisp):
(defun print-items (items)
  (dolist (item items)
    (message \"%%s\" item)))          ; Emacs Lisp syntax

Red Flags in Generated Code:
  ‚ö†Ô∏è  format t              ‚Üí Should be: message
  ‚ö†Ô∏è  (loop for ...)        ‚Üí Should be: dolist, dotimes, or cl-loop
  ‚ö†Ô∏è  defparameter          ‚Üí Should be: defvar
  ‚ö†Ô∏è  (incf x)              ‚Üí Should be: (cl-incf x) or (setq x (1+ x))
  ‚ö†Ô∏è  (decf x)              ‚Üí Should be: (cl-decf x) or (setq x (1- x))
  ‚ö†Ô∏è  remove-if without cl- ‚Üí Should be: cl-remove-if or seq-filter

Real Example - FizzBuzz:
AI might generate:
  (format t \"Fizz\")        ; ‚Üê BREAKS! Wrong dialect

Should be:
  (message \"Fizz\")         ; ‚Üê WORKS! Correct for Emacs

Quick Fix Strategy:
1. Search generated code for 'format t'
2. Replace with 'message'
3. Check for 'loop' ‚Üí use 'dolist' or 'cl-loop'
4. Test in *scratch* buffer before using

Better Prompts for Ellama:
  ‚úì 'Write EMACS LISP (not Common Lisp) code for...'
  ‚úì 'Use Emacs Lisp message function for output'
  ‚úì 'Use dolist and dotimes for iteration'
  ‚úì 'Follow Emacs Lisp conventions'

If you get Common Lisp code:
  ‚Üí Ask: 'Rewrite this for Emacs Lisp specifically'
  ‚Üí Ask: 'Replace Common Lisp functions with Emacs equivalents'"))

(demo-common-ai-mistakes)
#+END_SRC

** Quick Fixes for Common Mistakes

#+BEGIN_SRC emacs-lisp
(defun demo-quick-fixes ()
  "Quick fixes for common AI mistakes."
  (interactive)
  (message "Quick Reference: Fix AI-Generated Code

REPLACE THESE:
  (format t \"%%s\" x)      ‚Üí (message \"%%s\" x)
  (loop for ...)          ‚Üí (dolist ...)
  (defparameter x val)    ‚Üí (defvar x val)
  (incf x)                ‚Üí (cl-incf x) or (setq x (1+ x))
  (decf x)                ‚Üí (cl-decf x) or (setq x (1- x))
  (remove-if pred list)   ‚Üí (seq-filter (lambda (x) (not (pred x))) list)
  (remove-if-not p list)  ‚Üí (seq-filter p list)

EXAMPLE TRANSFORMATION:

Before (Common Lisp):
(defun sum-list (numbers)
  (loop for n in numbers
    sum n))

After (Emacs Lisp):
(defun sum-list (numbers)
  (cl-loop for n in numbers
    sum n))
;; Or better:
(defun sum-list (numbers)
  (apply #'+ numbers))

TESTING:
1. Copy AI-generated code to *scratch*
2. C-x C-e at end of expression
3. If error mentions 'stringp t' ‚Üí Common Lisp detected!
4. Ask Ellama to fix: 'Convert to Emacs Lisp'"))

(demo-quick-fixes)
#+END_SRC

** dotimes vs dolist Confusion

Local models frequently mix up `dotimes` and `dolist`:

#+BEGIN_SRC emacs-lisp
;; AI MISTAKE: Using dotimes with a list
(defun greet-wrong ()
  (let ((names '("Alice" "Bob")))
    (dotimes (name names)      ; ‚Üê WRONG! dotimes needs a NUMBER
      (message "Hello, %s!" name))))

;; Error: wrong-type-argument number-or-marker-p

;; CORRECT VERSION:
(defun greet-correct ()
  (let ((names '("Alice" "Bob")))
    (dolist (name names)       ; ‚Üê RIGHT! dolist for lists
      (message "Hello, %s!" name))))

(greet-correct)

(message "‚úì Remember: dotimes=numbers, dolist=lists")
#+END_SRC

** Iteration Cheat Sheet

#+BEGIN_SRC emacs-lisp
(defun demo-iteration-guide ()
  "Quick guide to Emacs iteration."
  (interactive)
  (message "Emacs Iteration Quick Reference:

dotimes - Count from 0 to N-1
  (dotimes (i 5)
    (message \"%%d\" i))
  ‚Üí 0, 1, 2, 3, 4

dolist - Iterate list elements
  (dolist (item '(a b c))
    (message \"%%s\" item))
  ‚Üí a, b, c

while - Loop with condition
  (let ((i 0))
    (while (< i 3)
      (message \"%%d\" i)
      (setq i (1+ i))))
  ‚Üí 0, 1, 2

cl-loop - Complex iteration (needs cl-lib)
  (cl-loop for i from 1 to 5
           collect (* i i))
  ‚Üí (1 4 9 16 25)

mapcar - Transform list
  (mapcar (lambda (x) (* x 2))
          '(1 2 3))
  ‚Üí (2 4 6)

Common Ellama Mistakes:
  ‚úó (dotimes (name names) ...)     ; Wrong type!
  ‚úì (dolist (name names) ...)      ; Correct

  ‚úó (dolist (i 10) ...)            ; Wrong type!
  ‚úì (dotimes (i 10) ...)           ; Correct"))

(demo-iteration-guide)
#+END_SRC

** AI Adds Unwanted Features

Ellama often generates extra code you didn't ask for:

#+BEGIN_SRC emacs-lisp
;; You ask for a simple function, get this:
(defgroup my-group nil           ; ‚Üê Not requested!
  "Settings"
  :group 'tools)

(defcustom my-var t              ; ‚Üê Not requested!
  "A variable"
  :type 'boolean)

(defun my-function ()            ; ‚Üê What you wanted
  (message "Hello"))

(provide 'my-function)           ; ‚Üê Not requested!

;; Problems:
;; - defgroup syntax often broken
;; - Adds complexity
;; - Harder to test

(message "Fix: Use restrictive prompts!")
#+END_SRC

** Restrictive Prompts for Ellama

#+BEGIN_SRC emacs-lisp
(defun demo-ellama-restrictive-prompts ()
  "How to get clean code from Ellama."
  (interactive)
  (message "Restrictive Prompts for Ellama:

BAD (Vague):
  'Write a function to greet people'

Result from local model:
  - Adds defgroup (often broken)
  - Adds defcustom
  - Adds provide statement
  - May mix Common Lisp syntax
  - Hard to extract working code

GOOD (Specific):
  'Write ONLY an Emacs Lisp function called greet-names.
   Do NOT add defgroup, defcustom, provide, or require.
   Use dolist to iterate over a list of names.
   Use message for output (NOT format t).
   This is EMACS LISP, not Common Lisp.
   Return only:
   (defun greet-names () ...body...)
   (greet-names)'

Result:
  - Just the function
  - Correct syntax
  - Easy to test

Key for Local Models:
  - Be VERY explicit
  - List what NOT to include
  - Specify dialect clearly
  - Show expected format
  - Keep it simple

Ellama-specific tip:
  Use ellama-code-edit on small snippets
  rather than generating large chunks.
  Easier to verify and fix!"))

(demo-ellama-restrictive-prompts)
#+END_SRC

** Performance Optimization

#+BEGIN_SRC emacs-lisp
(defun demo-performance-tips ()
  "Performance optimization tips."
  (interactive)
  (message "Performance Tips:

1. Model Selection:
   Fast: mistral, phi (quick responses)
   Balanced: llama3.2 (good quality/speed)
   Quality: deepseek-coder (best for complex code)

2. Context Size:
   - Shorter prompts = faster responses
   - Don't paste huge code blocks unnecessarily
   - Use ellama-ask-selection for specific parts

3. Streaming:
   - Responses stream in real-time
   - You see output as it's generated
   - Cancel with C-g if needed

4. Session Management:
   - Don't keep too many sessions
   - Clean old sessions periodically
   - M-x ellama-session-remove

5. Ollama Settings:
   - Ensure Ollama has adequate resources
   - Configure in ~/.ollama/config.json
   - Monitor with: ollama ps

6. Emacs Performance:
   - Use Emacs daemon for faster startup
   - Close unnecessary buffers
   - Consider faster-rendering markdown modes

Benchmarking:
(benchmark-run 1
  (ellama-chat))"))

(demo-performance-tips)
#+END_SRP

** Common Pitfalls

#+BEGIN_SRC emacs-lisp
(defun demo-common-pitfalls ()
  "Common pitfalls and solutions."
  (interactive)
  (message "Common Pitfalls:

‚ùå Ollama Not Running
   ‚úì Check: curl http://localhost:11434
   ‚úì Fix: ollama serve

‚ùå Model Not Found
   ‚úì Check: ollama list
   ‚úì Fix: ollama pull llama3.2

‚ùå Slow Responses
   ‚úì Check model size (smaller = faster)
   ‚úì Try: mistral instead of llama2
   ‚úì Reduce prompt length

‚ùå Out of Memory
   ‚úì Use smaller model
   ‚úì Close other applications
   ‚úì Increase Ollama memory limit

‚ùå Responses Cut Off
   ‚úì Model's context window limit
   ‚úì Start new session
   ‚úì Split into smaller queries

‚ùå Wrong Language Response
   ‚úì Set: (setopt ellama-language \"English\")
   ‚úì Or specify in prompt

‚ùå Code Suggestions Don't Work
   ‚úì Use code-specific model: codellama
   ‚úì Be more specific in prompts
   ‚úì Provide more context

‚ùå Can't Load Old Sessions
   ‚úì Check: ellama-sessions-directory
   ‚úì Verify files exist: ls ~/.emacs.d/ellama-sessions"))

(demo-common-pitfalls)
#+END_SRC

* Model Comparison

** Comparing Different Models

#+BEGIN_SRC emacs-lisp
(defun demo-model-comparison ()
  "Compare different Ollama models."
  (interactive)
  (message "Model Comparison Guide:

üöÄ SPEED (Fastest to Slowest)
  1. phi (1-3B params)       - Lightning fast
  2. mistral (7B)            - Very fast
  3. llama3.2 (8B)           - Fast
  4. codellama (7-13B)       - Medium
  5. llama2 (13B)            - Medium-slow
  6. deepseek-coder (6.7B)   - Medium

üéØ CODE QUALITY (Best to Good)
  1. deepseek-coder          - Excellent for code
  2. codellama               - Great for code
  3. llama3.2                - Good general + code
  4. starcoder2              - Good for code
  5. mistral                 - Decent for code
  6. llama2                  - Basic code support

üí¨ CHAT QUALITY
  1. llama3.2                - Excellent conversation
  2. llama2                  - Good conversation
  3. nous-hermes             - Instruction following
  4. mistral                 - Good general chat
  5. codellama               - Code-focused

üíæ MEMORY USAGE (Smallest to Largest)
  phi < mistral < llama3.2 < codellama < llama2

üìä RECOMMENDATIONS:

General Use:
  ‚Üí llama3.2 (best balance)

Pure Coding:
  ‚Üí deepseek-coder or codellama

Quick Tasks:
  ‚Üí mistral or phi

Learning:
  ‚Üí llama3.2 (good explanations)

Limited RAM:
  ‚Üí phi or mistral (smaller models)

Test different models:
(setopt ellama-provider
        (make-llm-ollama :chat-model \"MODEL-NAME\"))"))

(demo-model-comparison)
#+END_SRC

* Integration with Other Tools

** Combining with Org-mode

#+BEGIN_SRC emacs-lisp
(defun demo-org-integration ()
  "Demonstrate using Ellama with org-mode."
  (interactive)
  (message "Ellama + Org-mode Integration:

Use Case 1: Research Notes
  1. Create org file: research.org
  2. Write heading: * Understanding Macros
  3. M-x ellama-chat
  4. Ask questions, paste responses into org

Use Case 2: Code Documentation
  #+BEGIN_SRC emacs-lisp
  (defun my-function ...)
  #+END_SRC

  Select code ‚Üí ellama-ask-selection
  'Document this for README'
  Paste result into org

Use Case 3: TODO Generation
  * Project Tasks
  M-x ellama-chat
  'Generate TODO list for implementing a cache system'
  Copy as org TODOs

Use Case 4: Meeting Notes
  * Meeting with Bob
  M-x ellama-summarize
  Summarizes meeting notes

Use Case 5: Learning Journal
  * Daily Learning - 2025-01-03
  ** Learned about advice
  [Your notes]
  M-x ellama-ask-selection
  'Quiz me on this material'

Org-babel Integration:
  Since Ellama responses are text,
  copy into org src blocks for execution"))

(demo-org-integration)
#+END_SRC

** Combining with Other AI Tools

#+BEGIN_SRC emacs-lisp
(defun demo-tool-combination ()
  "How Ellama compares/combines with other tools."
  (interactive)
  (message "Ellama vs Other AI Tools:

Ellama vs gptel:
  Ellama: More commands, Ollama-focused, local-first
  gptel: Simpler, multiple backends, cloud-friendly
  ‚Üí Use both! gptel for cloud APIs, Ellama for local

Ellama vs org-ai:
  Ellama: Standalone, many commands
  org-ai: Org-mode native, inline AI
  ‚Üí Complement each other

Ellama vs aider:
  Ellama: In-Emacs, interactive
  aider: Git-focused, autonomous edits
  ‚Üí Different use cases

Combined Workflow:
  1. Use Ellama for exploration and learning
  2. Use gptel for quick cloud API queries
  3. Use org-ai for notes and documentation
  4. Use aider for large refactorings

Example:
  - Explore ideas: Ellama
  - Document: org-ai
  - Implement: aider
  - Quick questions: gptel

All tools complement each other!"))

(demo-tool-combination)
#+END_SRC

* Conclusion

** Summary and Next Steps

#+BEGIN_SRC emacs-lisp
(defun demo-summary ()
  "Summary and next steps."
  (interactive)
  (message "Ellama Summary:

‚úÖ What You Learned:
   - Installing and configuring Ellama
   - Basic and advanced commands
   - Working with different models
   - Practical workflows
   - Best practices and tips

üéØ Key Takeaways:
   - Ellama uses local Ollama models (private!)
   - Many specialized commands for different tasks
   - Session management for conversation history
   - Works great with org-mode
   - Complements other AI tools

üöÄ Next Steps:
   1. Install Ollama: https://ollama.ai/
   2. Pull a model: ollama pull llama3.2
   3. Install Ellama: M-x package-install RET ellama
   4. Try basic chat: M-x ellama-chat
   5. Explore commands: M-x ellama- TAB
   6. Read code examples in this document
   7. Execute examples with C-c C-c
   8. Experiment with your own prompts

üìö Resources:
   - Ellama: https://github.com/s-kostyaev/ellama
   - Ollama: https://ollama.ai/
   - Models: https://ollama.ai/library
   - Community: r/emacs, emacs.stackexchange.com

üí° Practice Ideas:
   - Refactor a real function in your codebase
   - Generate documentation for a project
   - Learn a new elisp concept interactively
   - Create a custom workflow for your needs

Happy AI-assisted Emacs hacking! üéâ"))

(demo-summary)
#+END_SRC

* Local Variables                                                  :ARCHIVE:
# Local Variables:
# eval: (org-babel-do-load-languages 'org-babel-load-languages '((emacs-lisp . t) (shell . t)))
# End:
