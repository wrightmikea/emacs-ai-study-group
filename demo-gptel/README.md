# gptel Demo

This project demonstrates [gptel](https://github.com/karthink/gptel), a simple LLM client for Emacs, with comprehensive testing examples using both mocks and local LLM integration.

## Overview

gptel is a simple, no-frills LLM client for Emacs that supports:
- ChatGPT (OpenAI API)
- Claude (Anthropic API)
- Gemini (Google AI API)
- Local models via Ollama, Llama.cpp, and others

## What's Included

### ðŸ“š Documentation

- **[docs/gptel-babel-demo.org](./docs/gptel-babel-demo.org)** - **NEW!** Interactive gptel demo with babel blocks
  - 8+ working examples (code generation, review, debugging, testing)
  - Executable with `C-c C-c` in Emacs
  - Exports to beautiful HTML
  - Includes mock framework examples
- **[docs/demo.org](./docs/demo.org)** - Interactive demonstration with executable babel blocks
- **[docs/testing-guide.org](./docs/testing-guide.org)** - Comprehensive testing guide with validation examples
- **[docs/README-EXPORT.md](./docs/README-EXPORT.md)** - Guide for exporting org files to HTML
- **[elisp/setup.el](./elisp/setup.el)** - Complete setup configuration for all backends

### ðŸ§ª Testing Suite

- **[tests/gptel-ollama-ert.el](./tests/gptel-ollama-ert.el)** - **NEW!** Comprehensive ERT test suite with:
  - 16 ERT tests covering unit, mock, and integration testing
  - Mock/spy framework for testing without LLM
  - Integration tests for Ollama
  - Proper test tagging (`:unit`, `:mock`, `:integration`, `:slow`)

- **[tests/SETUP-GUIDE.md](./tests/SETUP-GUIDE.md)** - **NEW!** Complete setup and usage guide
- **[tests/README.md](./tests/README.md)** - Overview of all test files
- **[tests/test-automated-ollama.el](./tests/test-automated-ollama.el)** - Automated AI code generation testing
- **[tests/results/](./tests/results/)** - Captured test results with timestamps

## Quick Start

### Option 1: Try It Interactively (Org-mode)

```bash
cd docs

# New interactive babel demo with AI examples
emacs gptel-babel-demo.org
# Execute code blocks with C-c C-c
# Export to HTML with C-c C-e h h

# Or try the testing guide
emacs testing-guide.org
```

### Option 2: Run Unit Tests (No LLM Required)

```bash
cd tests
emacs -Q -batch -L . -l gptel-ollama-ert.el \
  -f ert-run-tests-batch-and-exit
```

This runs **fast unit tests with mocks** - no Ollama or API keys needed!

### Option 3: Run Integration Tests (Requires Ollama)

```bash
# 1. Start Ollama
ollama serve

# 2. Pull a model
ollama pull llama3.2

# 3. Run tests
cd tests
emacs -Q --eval "(progn
  (load-file \"gptel-ollama-ert.el\")
  (gptel-test-run-integration))"
```

## Features

### ðŸŽ¯ Mock Testing Framework

Test your AI-integrated code without making real API calls:

```elisp
;; Enable mocking
(gptel-test--enable-mock)

;; Add mock responses
(gptel-test--add-mock "What is 2+2?" "The answer is 4.")

;; Test your code with predictable responses
(gptel-request "What is 2+2?"
  :callback (lambda (response info)
             (message "Got: %s" response)))

;; Spy on calls
gptel-test--spy-calls  ; See all API calls made
```

### ðŸ”¬ Integration Testing

Test with real Ollama LLM:

```elisp
(ert-deftest my-integration-test ()
  :tags '(:integration :slow)
  (skip-unless (gptel-test--check-ollama-available))

  (let* ((result (gptel-test--sync-request "Say hello"))
         (response (car result))
         (success (cdr result)))
    (should success)
    (should (stringp response))))
```

### âœ… Code Validation

Automatically validate AI-generated Elisp code:

```elisp
(defun validate-elisp-function (code)
  "Validate CODE for common AI mistakes."
  ;; Checks for Python syntax (%, ==, return)
  ;; Validates parentheses
  ;; Tests evaluation
  ...)
```

## Test Categories

- **:unit** - Fast tests, no external dependencies
- **:mock** - Tests using mock LLM responses
- **:integration** - Tests with real Ollama (slow, requires server)
- **:slow** - Tests that may take 30+ seconds

## Setup

### Basic Setup (Any LLM Provider)

1. Install gptel from MELPA:
   ```elisp
   M-x package-install RET gptel RET
   ```

2. Load configuration:
   ```elisp
   (load-file "demo-gptel/elisp/setup.el")
   ```

3. Configure your preferred backend (see [elisp/setup.el](./elisp/setup.el))

### Local LLM Setup (Ollama)

See [tests/SETUP-GUIDE.md](./tests/SETUP-GUIDE.md) for detailed instructions.

**Quick version:**

```bash
# Install Ollama
brew install ollama  # macOS
# or visit https://ollama.ai for other platforms

# Start server
ollama serve

# Pull a model
ollama pull llama3.2
```

## Documentation

- **[gptel Babel Demo (Org)](./docs/gptel-babel-demo.org)** - **NEW!** Interactive AI examples with HTML export
- **[Export Guide](./docs/README-EXPORT.md)** - How to export org files to HTML
- **[Testing Guide (Org)](./docs/testing-guide.org)** - Interactive testing examples
- **[Setup Guide](./tests/SETUP-GUIDE.md)** - Detailed testing setup
- **[Elisp Development Guide](../docs/elisp-development.md)** - Best practices for developing Elisp with AI coding agents
- **[Test Results README](./tests/README.md)** - Understanding test outputs

## Resources

- [gptel GitHub](https://github.com/karthink/gptel)
- [gptel Manual](https://github.com/karthink/gptel/wiki)
- [Ollama](https://ollama.ai)
- [ERT Manual](https://www.gnu.org/software/emacs/manual/html_node/ert/)

## Project Structure

```
demo-gptel/
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ gptel-babel-demo.org       # Interactive babel demo (NEW!)
â”‚   â”œâ”€â”€ README-EXPORT.md           # Export guide (NEW!)
â”‚   â”œâ”€â”€ export-to-html.el          # Export script (NEW!)
â”‚   â”œâ”€â”€ export.sh                  # Bash export script (NEW!)
â”‚   â”œâ”€â”€ style.css                  # HTML styling (NEW!)
â”‚   â”œâ”€â”€ demo.org                   # Interactive demo
â”‚   â””â”€â”€ testing-guide.org          # Testing guide with examples
â”œâ”€â”€ elisp/
â”‚   â””â”€â”€ setup.el                   # Configuration examples
â””â”€â”€ tests/
    â”œâ”€â”€ SETUP-GUIDE.md             # Testing setup guide
    â”œâ”€â”€ README.md                  # Test overview
    â”œâ”€â”€ gptel-ollama-ert.el        # ERT test suite
    â”œâ”€â”€ test-automated-ollama.el   # Automated testing
    â”œâ”€â”€ test-ollama-fizzbuzz.el    # Static unit tests
    â””â”€â”€ results/                   # Test result files
```

## Contributing

We welcome contributions! Areas of interest:

- Additional test cases
- Examples with different LLM providers
- Documentation improvements
- Common AI mistake patterns
- Performance benchmarks

## Examples from Test Results

Real examples of AI-generated code captured by our tests:

### Example 1: Common Mistake (Python Syntax)

**AI Generated:**
```elisp
(defun fizzbuzz (n)
  (if (i % 3 == 0) "Fizz" "Buzz"))
```

**Issues:**
- Uses `%` operator (Python/C syntax, not Elisp)
- Uses `==` operator (not Elisp)

**Corrected:**
```elisp
(defun fizzbuzz (n)
  (if (zerop (mod i 3)) "Fizz" "Buzz"))
```

### Example 2: Successful Generation

**AI Generated:**
```elisp
(defun add-two-numbers (a b)
  "Add A and B."
  (+ a b))
```

**Status:** âœ“ Valid Elisp, evaluates successfully

See [tests/results/](./tests/results/) for more real examples!

## Next Steps

1. **Try the gptel babel demo:** Open `docs/gptel-babel-demo.org` and execute AI examples
2. **Export to HTML:** Run `cd docs && ./export.sh` to create shareable HTML
3. **Try the testing guide:** Open `docs/testing-guide.org` and execute the babel blocks
4. **Run unit tests:** See what mocking looks like without needing an LLM
5. **Install Ollama:** Try integration tests with a real local LLM
6. **Write your own examples:** Use the templates provided
7. **Share your findings:** Contribute back to the study group

---

**Part of the [Emacs AI Study Group](../../README.md)**
